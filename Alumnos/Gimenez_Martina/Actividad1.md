Temática: Análisis de Sesgos en Modelos Predictivos

Problemática
    El uso creciente de modelos predictivos en la toma de decisiones ha evidenciado la presencia de sesgos que afectan la equidad y la justicia en los resultados, impactando negativamente a ciertos grupos o poblaciones. La investigación busca cuantificar y analizar estos sesgos para entender su origen y evaluar su impacto en la precisión y equidad de los modelos predictivos en diversos contextos.

Objetivos
    General
        Evaluar y cuantificar la presencia de sesgos en modelos predictivos, identificando su impacto en la precisión y equidad de las decisiones tomadas a partir de dichos modelos en contextos específicos.
    Especificos
        - Identificar y caracterizar las fuentes principales de sesgo en modelos predictivos a partir de conjuntos de datos de entrenamiento y pruebas.
        - Medir la magnitud del sesgo mediante métricas cuantitativas de equidad y desempeño.
        - Evaluar el impacto del sesgo en la toma de decisiones basada en modelos predictivos.
        - Proponer y aplicar técnicas cuantitativas para la reducción y corrección del sesgo en los modelos.

Alcance
    Este estudio se centrará en el análisis de sesgos en modelos predictivos en un contexto específico, como la selección de personal o la evaluación crediticia. Se utilizarán conjuntos de datos relevantes y representativos para garantizar que los resultados sean aplicables a situaciones del mundo real. La investigación abordará tanto el análisis estadístico de los sesgos identificados como la implementación de técnicas de mitigación, proporcionando recomendaciones prácticas para su reducción. Sin embargo, el estudio no abordará la implementación de modelos en producción, ni explorará todos los posibles contextos donde se pueden aplicar modelos predictivos.

Estado del arte
    Las fuentes para construir el estado del arte provienen principalmente de artículos académicos, documentos de trabajo e informes de investigación, publicados en revistas especializadas y por universidades o institutos de investigación. Los años de estas investigaciones reflejan un interés creciente y contemporáneo en la temática. Estas publicaciones están hechas entre 2017 hasta 2025.

    1. Introducción al estado del arte
        La creciente proliferación de tecnologías basadas en Big Data e Inteligencia Artificial (IA) ha revolucionado la capacidad de las organizaciones para recopilar, procesar y analizar grandes volúmenes de datos, lo que ha llevado al desarrollo de sofisticados modelos predictivos. Estos modelos son herramientas esenciales para la toma de decisiones estratégicas en diversos campos, incluyendo la administración tributaria, la seguridad, la salud, las finanzas y las ciencias sociales. Sin embargo, a pesar de su enorme potencial para optimizar procesos y generar conocimiento, existe una preocupación creciente sobre la presencia inherente y las implicaciones de los sesgos en estos sistemas. Los datos, por sí mismos, no son entidades puras; son recolectados, interpretados, analizados y presentados por personas, y en el caso del Big Data, con la ayuda de la IA, lo que los hace susceptibles a la influencia de sesgos y falacias. Este estado del arte busca identificar y caracterizar los sesgos más comunes, sus orígenes, impactos y las estrategias para su mitigación en el contexto de los modelos predictivos.

    2. Concepto y Manifestaciones del Sesgo en Modelos Predictivos
        Un sesgo en el contexto de los modelos predictivos y el análisis de datos se define generalmente como un defecto de interpretación en el que se asigna un valor desigual a favor o en contra de determinadas conclusiones, obtenidas a partir de un conjunto específico de datos. Estos sesgos son, en muchos casos, sistemáticos y no aleatorios. La creencia de que una gran cantidad de datos garantiza objetividad es engañosa, ya que los investigadores son siempre intérpretes de datos y el proceso de "limpieza de datos" es inherentemente subjetivo. Los sistemas de IA y los algoritmos no son autónomos de lo humano; son instrumentos de medición y percepción que pueden difractar y distorsionar el objeto observado a través de "lentes", reproduciendo sesgos presentes en los datos con los que son entrenados.

    3. Tipos y Orígenes de los Sesgos
        Los sesgos en los modelos predictivos pueden originarse en distintas etapas del proceso, desde la recolección y selección de datos hasta la interpretación de los resultados. Pasquinelli y Joler (2020) distinguen entre tres tipos principales:
            - Sesgos Históricos o de Mundo: Refieren al contexto de exclusión y discriminación social existente fuera del sistema computarizado. Estos sesgos estructurales pueden trasladarse directamente al funcionamiento de los sistemas automatizados.
            - Sesgos de Datos: Surgen cuando los programadores introducen exclusiones al entrenar los sistemas de IA. Pueden basarse en taxonomías hegemónicas que malinterpretan la diversidad social o reproducen jerarquías, por ejemplo, estereotipos de género o raciales. Los datos recolectados pueden no reflejar la población de estudio con exactitud, llevando a conclusiones parciales.
            - Sesgos Algorítmicos (o Estadísticos): Relacionados con el propio modelo de programación en el que se basa el aprendizaje automatizado. Los algoritmos, en su proceso de "compresión de información", sustraen y representan la realidad, lo que puede llevar a una "pérdida de la diversidad cultural" y la reproducción de desigualdades o errores.

        Otros tipos de sesgos identificados incluyen:
            - Sesgo de Sobrea juste (Overfitting): Ocurre cuando un modelo estadístico y matemático se corresponde casi totalmente con su conjunto de entrenamiento (dataset), lo que lo hace fallar al incorporar nueva información y realizar generalizaciones.
            - Sesgo de Supervivencia (Survivorship Bias): Tendencia a enfocarse solo en elementos "sobrevivientes", excluyendo aquellos que ya no aportan o no existen debido a un rendimiento deficiente, lo que puede generar una visión excesivamente optimista.
            - Error de McNamara: Prioriza métricas y datos cuantitativos fáciles de cuantificar, bajo una supuesta objetividad, ignorando factores cualitativos cruciales. Esto puede llevar a conclusiones simplistas y estrategias fallidas.
            - Sesgos de Género Ocultos: Se han detectado en macrodatos textuales (como Wikipedia) mediante redes neuronales, donde la geometría de los "encajes de palabras" (word embeddings) reproduce el sexismo estructural del lenguaje, asociando, por ejemplo, "Hombre es a experto como mujer es a sabelotodo" o "Hombre es a trabajo como mujer es a madre". Estos sesgos revelan una "desigualación semántica de género" y pueden influir en decisiones como la contratación. También se observan sesgos en el reconocimiento facial, donde los sistemas son menos sensibles a rostros de piel oscura y de mujer.

    4. Impacto de los Sesgos en Modelos Predictivos
        Los sesgos en los modelos predictivos pueden tener repercusiones negativas significativas en la vida y oportunidades de los ciudadanos, especialmente en grupos marginalizados, y generar un impacto adverso en las sociedades y empresas.
        - Discriminación: La automatización de decisiones puede conducir a discriminación algorítmica. Por ejemplo, sistemas de predicción de reincidencia criminal pueden reforzar sesgos raciales y socioeconómicos, o algoritmos de reclutamiento pueden excluir perfiles de forma discriminatoria.
        - Errores en la Toma de Decisiones: Los sesgos pueden llevar a conclusiones o predicciones algorítmicas erróneas. Esto se ha observado en el cálculo de riesgos fiscales, en la gestión de una pandemia al enfocarse en métricas simplistas, o en sistemas de salud al identificar pacientes prioritarios.
        - Daños a la Reputación y Financieros: Consecuencias como pérdidas financieras derivadas de predicciones erróneas o daños a la reputación del contribuyente, así como la pérdida de confidencialidad de datos y brechas de seguridad digital.

    5. Detección y Mitigación de Sesgos
        Es fundamental abordar los sesgos para mejorar la calidad de las decisiones y la ética en el campo del Big Data. Las fuentes proponen diversas estrategias:
        - Conciencia Crítica y Reflexión Epistemológica: Reconocer que los datos no son neutros ni objetivos, sino productos de relaciones y marcos epistemológicos. Es crucial enmarcar los datos en contextos, narrativas e intereses específicos.
        - Mejora de la Calidad de los Datos: El aprendizaje automático depende de la calidad, objetividad y tamaño de los datos de entrenamiento. Datos deficientes o incompletos resultarán en predicciones inexactas. Es esencial el preprocesamiento de datos para explorar sus características y decidir sobre modelos adecuados.
        - Transparencia Algorítmica y Rendición de Cuentas: Exigir transparencia y rendición de cuentas en la toma de decisiones automatizadas. Esto incluye la necesidad de comprender cómo se construyen estos sistemas de observación y la programación de algoritmos.
        - Evaluaciones de Impacto: Implementar técnicas preventivas como los Privacy Impact Assessment (PIA) y extenderlas a "discrimination impact assessments" o "social impact assessments". Estas evaluaciones deberían ser obligatorias para usos de Big Data que implican perfiles o decisiones con efectos jurídicos.
        - Diversidad e Interdisciplinariedad en los Equipos: Aumentar la diversidad en la composición de los equipos de trabajo y de investigación, incluyendo expertos de distintas disciplinas, para mejorar la creatividad, el sentido crítico y garantizar que los sistemas de IA incorporen principios de equidad y transparencia.
        - Técnicas de Desaprendizaje y Ajuste: Desarrollar algoritmos que invaliden sesgos étnicos, de género o edad. Esto incluye la mitigación de sesgos en los corpus lingüísticos de entrenamiento y el ajuste de parámetros en los modelos.
        - Triangulación Metodológica: Combinar enfoques cuantitativos y cualitativos para enriquecer la comprensión de los fenómenos y contrarrestar subjetividades.
        - Documentación de Datos: Implementar "datasheets for datasets" que documenten el origen y las limitaciones de los datos utilizados.

    6. Contextos de Aplicación y Desafíos
        Los modelos predictivos y el análisis de Big Data se aplican en múltiples sectores, cada uno con sus desafíos particulares en cuanto a sesgos:
        - Administraciones Tributarias: Uso de algoritmos para detectar fraude fiscal y crear perfiles de riesgo, lo que plantea preocupaciones sobre el tratamiento de datos personales, sesgos y discriminación. La Agencia Tributaria española utiliza análisis de Big Data para reducir errores en declaraciones de IRPF y gestionar riesgos fiscales.
        - Seguridad y Defensa: Predicción de la comisión de delitos y seguimiento de actividades sospechosas. Aquí, los sesgos pueden llevar a clasificaciones discriminatorias, como en el caso "Machine Bias", que mostró sesgos raciales en la predicción de reincidencia criminal.
        - Salud Pública y Epidemiología: Los modelos predictivos pueden mejorar la vigilancia de enfermedades y personalizar tratamientos. Sin embargo, la calidad de los datos es crucial para evitar diagnósticos imprecisos y asegurar decisiones justas. El análisis de Big Data genera conocimiento en tiempo real para mejorar la seguridad y eficiencia de la atención sanitaria.
        - Ciencias Sociales: La sociología puede beneficiarse del Big Data para el conteo de fenómenos y la predicción de comportamientos. No obstante, es fundamental superar el reduccionismo y la "cuantifrenia", integrando la teoría social con las habilidades informáticas y estadísticas. Los datos de Internet y redes sociales son fuentes valiosas, pero el acceso desigual y los problemas de consentimiento informado son retos éticos.

    7. Marco Ético y Legal
        El abordaje de los sesgos en modelos predictivos exige una sólida base ética y jurídica.
            - Regulaciones de Protección de Datos: Normativas como el Reglamento General de Protección de Datos (GDPR) en la UE y la California Consumer Privacy Act (CCPA) en EE. UU. buscan proteger los datos personales y exigir transparencia y consentimiento informado. La UE ha publicado directrices éticas y un Libro Blanco sobre IA, articulando un marco común para una IA ética y fiable basada en derechos humanos.
            - Derechos Fundamentales: Los principios constitucionales y los derechos y libertades de las sociedades democráticas deben ser el punto de partida para orientar las respuestas futuras. Se plantea la necesidad de una readecuación de estos principios y el reconocimiento de nuevos derechos, como el derecho a la criptografía.
            - Transparencia y Explicabilidad (Explainability): La dificultad de acceder a los algoritmos, datos y conocimientos generados, incluso por parte de los poderes públicos, resalta la necesidad de una respuesta jurídica que fundamente cómo y en qué medida se puede acceder a esta información. Esto incluye el derecho a la explicación y la transparencia de las decisiones automatizadas.
            - Autorregulación y Heterorregulación: Se discute la eficacia de modelos de autorregulación o heterorregulación, códigos y normas de conducta para limitar usos poco éticos.

    8. Retos y Direcciones Futuras
        A pesar de los avances, persisten importantes retos y áreas de investigación:
            - Mejora de la Calidad Algorítmica: Es necesario mejorar el diseño interno de los algoritmos para evitar discriminaciones y asegurar que los modelos predictivos sean más objetivos y justos. Los modelos basados en situaciones pasadas siempre tendrán un margen de error.
            - Profundización en Estadística y Lógica Formal: Algunas falacias y paradojas, como la Paradoja de Simpson, demandan un enfoque más profundo en estadística y lógica formal para su correcto análisis y cuantificación de relaciones causales.
            - Investigación Empírica: El análisis conceptual y bibliográfico puede ampliarse mediante estudios de caso, encuestas y entrevistas en el ámbito privado y público para comprender mejor la prevalencia de errores y desarrollar estrategias efectivas de mitigación.
            - Legitimidad Epistemológica del Big Data: Explorar el rol de la ética en la interpretación de sesgos, falacias y paradojas, y la legitimidad epistemológica del Big Data, enfocándose en su carácter científico derivado de los procesos analíticos y de visualización.
            - Consideraciones Sociológicas y Culturales: La investigación debería profundizar en aspectos como la cultura organizacional, las consideraciones sociológicas y la teoría del poder que influyen en la manifestación de errores lógicos.
            - Nuevos Mecanismos Legales: Articular mecanismos legales que aseguren la implementación de una IA que respete los derechos y garantías de los ciudadanos y los principios éticos establecidos, como la aplicación fiable, robusta y centrada en el ser humano.

    9. Conclusión del estado del arte
        El análisis de sesgos en modelos predictivos es un campo de investigación crucial y en constante evolución. Si bien el Big Data y la IA ofrecen herramientas poderosas para la toma de decisiones, la presencia de sesgos, ya sean históricos, de datos o algorítmicos, es una realidad ineludible que puede perpetuar y exacerbar desigualdades y llevar a conclusiones erróneas. Es imperativo que los profesionales y organizaciones adopten un enfoque crítico, transparente y multidisciplinario, implementando marcos éticos y legales robustos, promoviendo la diversidad en los equipos de desarrollo y utilizando metodologías que permitan la detección y mitigación efectiva de estos sesgos. Solo así se podrá aprovechar el verdadero potencial de estas tecnologías para el beneficio de la sociedad, garantizando que el conocimiento generado sea justo, equitativo y fiel a la complejidad de la realidad.